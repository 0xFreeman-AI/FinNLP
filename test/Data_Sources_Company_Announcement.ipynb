{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from lxml import etree\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "class Annoumcement_Downloader:\n",
    "\n",
    "    def __init__(self, args = {}):\n",
    "        pass\n",
    "\n",
    "    def download(self, stock = \"all\",max_page = 100):\n",
    "        page = 0\n",
    "        df = pd.DataFrame()\n",
    "        print(f\"Getting page: \",end = \"\")\n",
    "        while page < max_page:\n",
    "            print(page, end = \" \")\n",
    "            headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/111.0\",\n",
    "                'Accept-Encoding':'gzip, deflate, br',}\n",
    "            url = f\"https://vip.stock.finance.sina.com.cn/corp/view/vCB_AllBulletin.php?stockid={stock}&Page={page}\"\n",
    "            response = requests.get(url = url,headers=headers)\n",
    "            # response.encoding = \"GBK\"\n",
    "            # print(response.content.decode('GBK'))\n",
    "            text = response.content.decode('GBK')\n",
    "            html = etree.HTML(text)\n",
    "\n",
    "            # get announcement date\n",
    "            date_list = html.xpath(\"/html/body/div[6]/div[2]/div[2]/table[2]/tr/td[2]/div[1]/ul/text()\")\n",
    "            if len(date_list) <= 0:\n",
    "                break\n",
    "            date_list = [date.strip('.\\r').strip('.\\n').strip('.\\xa0').strip(' ') for date in date_list]\n",
    "            date_list = [date for date in date_list if len(date) == 10]\n",
    "\n",
    "\n",
    "            # get headlines and urls\n",
    "            url_root = \"https://vip.stock.finance.sina.com.cn\"\n",
    "            a_list = html.xpath(\"/html/body/div[6]/div[2]/div[2]/table[2]/tr/td[2]/div[1]/ul/a\")\n",
    "            headline_list = [a.xpath(\"./text()\")[0] for a in a_list ]\n",
    "            url_list = [url_root + a.xpath(\"./@href\")[0] for a in a_list ]\n",
    "            \n",
    "            tmp_df = {\n",
    "                \"date\": date_list,\n",
    "                \"headline\": headline_list,\n",
    "                \"url\": url_list,\n",
    "            }\n",
    "            tmp_df = pd.DataFrame(tmp_df)\n",
    "            df = pd.concat([df,tmp_df])\n",
    "            page += 1\n",
    "        \n",
    "        \n",
    "        with tqdm(total = df.shape[0],desc = \"Getting annoumcement content\" ) as pbar:\n",
    "            df[\"content\"] = df.apply(lambda x: self.get_content(x,pbar), axis=1 )\n",
    "        \n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        return df\n",
    "        \n",
    "    def get_content(self,x,pbar,delay = 0.1):\n",
    "        time.sleep(delay)\n",
    "        url = x.url\n",
    "        headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/111.0\",\n",
    "                'Accept-Encoding':'gzip, deflate, br',}\n",
    "        response = requests.get(url = url,headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                text = response.content.decode('GBK')\n",
    "                html = etree.HTML(text)\n",
    "\n",
    "                # clean content\n",
    "                content_list = html.xpath(\"//*[@id='content']//text()\")\n",
    "                content_list = [content.strip('.\\t').strip('.\\n').strip('.\\r') for content in content_list]\n",
    "                content_list = [content for content in content_list if len(content) != 0]\n",
    "                content = \"\".join(content_list)\n",
    "            except:\n",
    "                return \"can't get content\"\n",
    "        else:\n",
    "            return \"can't get content\"\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "        return content\n",
    "\n",
    "    def clean_data(self):\n",
    "        pass\n",
    "\n",
    "    def transfer_standard_date_to_nonstandard(self,date):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader = Annoumcement_Downloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = \"600519\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page: 0 1 2 3 4 5 6 7 8 9 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d16cf87acb4a4bab38bcb458d5013c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting annoumcement content:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = downloader.download(stock,max_page=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"df.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afd6dc03c9be451573fc2885de79a969af6a24a159f11a3ead741ab7a9ff405f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
